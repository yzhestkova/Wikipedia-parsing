{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code suggest the most basic cleaning of Wikipedia articles text after \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treat this code as a continuation of \"Extracting Wikipedia articles text from dumps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas datafrfame constists of title column and text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=timer()\n",
    "for j in range(0,57):\n",
    "    print(\"Processing partition {}\".format(j)) \n",
    "\n",
    "    df = pd.read_csv(r'output'+str(j)+'.csv')\n",
    "    \n",
    "    #We need only text of articles, not their supplemental material\n",
    "    Search_for_These_values = ['File:','Category:','Template:','Wikipedia'] \n",
    "    pattern = '|'.join(Search_for_These_values)\n",
    "    df = df.loc[~(df['title'].str.contains(pattern, case=False, na=False))].copy()\n",
    "    \n",
    "    #Get rid of all the XML related punctuation\n",
    "    df['text'].replace(to_replace=r'{{', value='{', inplace=True, regex=True)\n",
    "    df['text'].replace(to_replace=r'}}', value='}', inplace=True, regex=True)\n",
    "    df['text'].replace(to_replace=r'\\{.*?\\}', value='', regex=True, inplace=True)\n",
    "    df['text'].replace(to_replace=r'\\n', value='', inplace=True, regex=True)\n",
    "    df['text'].replace(to_replace=r'\\{.*?\\}', value='', regex=True, inplace=True)\n",
    "    df['text'].replace(to_replace=r'\\[\\[', value='', regex=True, inplace=True)\n",
    "    df['text'].replace(to_replace=r'\\]\\]', value='', regex=True, inplace=True)\n",
    "    df['text'].replace(to_replace=r'\\<.*?\\>', value='', regex=True, inplace=True)\n",
    "    \n",
    "    #Stop once you hit the end of the article's information content\n",
    "    df['text'] = df['text'].str.split('==References', n=1, expand=True)[0]\n",
    "    df['text'] = df['text'].str.split('==External links', n=1, expand=True)[0]\n",
    "    \n",
    "    #Some extra cleaning and we end up with text consisting only of meaningful words\n",
    "    df['text'].replace(to_replace=r'\\[http.*?\\]', value='', regex=True, inplace=True)\n",
    "    df['text'].replace(to_replace=r'File.*?\\s', value='', regex=True, inplace=True)\n",
    "    df['text'].replace(to_replace=r'[^A-Za-z0-9 ]+', value=' ', inplace=True, regex=True)\n",
    "    df['text']=df['text'].str.findall('\\w{5,}').str.join(' ')\n",
    "    export_csv = df.to_csv (r'cleaned'+str(j)+'.csv', index = None)\n",
    "    \n",
    "    del df\n",
    "    \n",
    "end=timer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
